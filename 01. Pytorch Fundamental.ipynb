{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4179,
     "status": "ok",
     "timestamp": 1727077817089,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "jsJ3DCHa2px_",
    "outputId": "30357a16-a094-4681-f123-a0bfd9331b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2RTcKZ13FfS"
   },
   "source": [
    "# Introduction to Tensors\n",
    "## Creating tensors\n",
    "Pytorch tensors are created using `torch.Tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1727077921981,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "xap2U3U62xvF",
    "outputId": "73965ebc-4d62-4951-c1c5-eb884593dd29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1727078076845,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "JuNLhBCF3a8-",
    "outputId": "3145f289-4c04-4703-effc-ac7864e59d28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim   # Scalar has no dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1727078096403,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "c2PapXRV4A1D",
    "outputId": "ec233228-8e90-4ff9-979e-cdcac3dcffd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()   # Get tensor back as Python int -> a tensor with 2 or more elements cannot be converted to Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1727078741853,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "AA9hRKs66g3Q",
    "outputId": "e3fe849c-d742-4c9b-e12b-50ba5c6fb586"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cak9OtmZ6tVj"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 449,
     "status": "ok",
     "timestamp": 1727078219553,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "iE0tuwM24FmA",
    "outputId": "b75e3c3e-0edb-40c2-9d0c-fbb3c360489e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 427,
     "status": "ok",
     "timestamp": 1727078265938,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "UO89INK84jl3",
    "outputId": "78a1395d-757c-489c-82ea-3bbf6c366f2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim   # Dimension is the number of square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1727078752468,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "05hPnzU34u8t",
    "outputId": "2eeef01f-45e0-452d-b5af-147cadc91615"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape    # Shape is the number of elements of each square brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71Vlp-Ym7O2C"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 440,
     "status": "ok",
     "timestamp": 1727079013221,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "wyyBnvSn7GTd",
    "outputId": "c180693e-3404-445f-880f-67034be3841a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[7, 8],\n",
    "                       [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1727079044425,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "a7MNEbej7XQJ",
    "outputId": "5304a816-e5ab-4271-b9b9-3c011a1d9b14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1727079073826,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "M7urOmd77tFB",
    "outputId": "6c0893d6-23b4-4828-8458-771ac2957111"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLXkfxqyBzz7"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1727080714286,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "zjn-7fuvBzUZ",
    "outputId": "06c976ca-555e-407c-b7a6-80b62b6f3d4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 6]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [3,6,9],\n",
    "                        [2,4,6]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1727080730994,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "QjFA4fO070I1",
    "outputId": "0730cbbf-5274-4945-98dd-a2a4c1f591c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1727080742232,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "_FxQ6EskCI7X",
    "outputId": "e3e76680-f433-42ba-a14f-49f630537486"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape   # shape는 각각의 bracket(dimansion) 안에 몇  개의 요소가 있느냐로 정의된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLTRRpoaD2Ki"
   },
   "source": [
    "## Random tensors\n",
    "Why randon tensors?\n",
    "\n",
    "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers.....`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1727082643988,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "s1T-XSX-CLYV",
    "outputId": "4d9a7b44-2a21-4371-c547-f531d4d3bcb5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9667, 0.8447, 0.9420, 0.9485],\n",
       "        [0.3980, 0.6571, 0.6869, 0.4383],\n",
       "        [0.5144, 0.3535, 0.7889, 0.8462]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of shape (3,4)\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1727083229955,
     "user": {
      "displayName": "황지은",
      "userId": "00972427378770874224"
     },
     "user_tz": -540
    },
    "id": "wREyMeggJb5o",
    "outputId": "2765330f-ad20-479c-8708-4919f311374a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3372, 0.3301, 0.3086],\n",
       "         [0.1654, 0.6810, 0.3374],\n",
       "         [0.9536, 0.3761, 0.5112],\n",
       "         ...,\n",
       "         [0.2486, 0.2138, 0.2916],\n",
       "         [0.2538, 0.6024, 0.0536],\n",
       "         [0.9148, 0.9891, 0.1178]],\n",
       "\n",
       "        [[0.9064, 0.3815, 0.1110],\n",
       "         [0.2610, 0.0445, 0.3244],\n",
       "         [0.1231, 0.0759, 0.4260],\n",
       "         ...,\n",
       "         [0.9266, 0.7186, 0.5547],\n",
       "         [0.6218, 0.1941, 0.1473],\n",
       "         [0.5506, 0.7822, 0.9083]],\n",
       "\n",
       "        [[0.0134, 0.7411, 0.6296],\n",
       "         [0.1803, 0.0419, 0.5088],\n",
       "         [0.2554, 0.3374, 0.7887],\n",
       "         ...,\n",
       "         [0.4339, 0.8293, 0.5806],\n",
       "         [0.6563, 0.1303, 0.8198],\n",
       "         [0.8800, 0.4294, 0.7863]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9522, 0.3679, 0.1692],\n",
       "         [0.6311, 0.9511, 0.5069],\n",
       "         [0.6791, 0.4304, 0.3226],\n",
       "         ...,\n",
       "         [0.1899, 0.8201, 0.8132],\n",
       "         [0.4059, 0.4402, 0.9717],\n",
       "         [0.4501, 0.0794, 0.8881]],\n",
       "\n",
       "        [[0.2311, 0.8966, 0.2800],\n",
       "         [0.0842, 0.0450, 0.8001],\n",
       "         [0.8454, 0.7990, 0.0408],\n",
       "         ...,\n",
       "         [0.3242, 0.6537, 0.1844],\n",
       "         [0.5207, 0.9154, 0.9139],\n",
       "         [0.8102, 0.2803, 0.7646]],\n",
       "\n",
       "        [[0.8376, 0.4740, 0.3905],\n",
       "         [0.0444, 0.4229, 0.1101],\n",
       "         [0.8229, 0.9031, 0.8029],\n",
       "         ...,\n",
       "         [0.9900, 0.8028, 0.1110],\n",
       "         [0.5110, 0.1687, 0.7072],\n",
       "         [0.4975, 0.3983, 0.3234]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(224,224,3)    # height, width, channel\n",
    "random_image_size_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L19YAghxLq9m"
   },
   "source": [
    "## Zeros and ones\n",
    "`torch.zeros()` and `torch.ones()` and `torch.rand()` are all torch.float32 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(3,4)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(1,3,3)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a range of tensors and tensors-like\n",
    "`torch.arange()` is similar with range in python. `torch.zeros_like()` makes a tensor with zeros in the same shape of input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_nine = torch.arange(10)    # similar with range in python \n",
    "zero_to_nine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_nine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros = torch.zeros_like(input = zero_to_nine)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information from tensors\n",
    "the default datatype of tensors is `torch.float32`    \n",
    "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch\n",
    "1. Tensors not right datatype `tensor.dtype`\n",
    "2. Tensors not right shape `tensor.shape` = `tensor.size()`\n",
    "3. Tensors not on the right device `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None,    # what datatype is the tensor (ex. float32, float16)\n",
    "                              device='cpu',    # what device is your tensor on. cpu by default\n",
    "                              requires_grad=False)   # whether or not track gradients with this tensors operations    \n",
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9., 36., 81.])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor_operated = float_32_tensor * float_16_tensor\n",
    "print(tensor_operated)\n",
    "print(tensor_operated.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9., 36., 81.])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor_operated = float_32_tensor * int_32_tensor\n",
    "print(tensor_operated)\n",
    "print(tensor_operated.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_tensor = torch.tensor([3, 6, 9], dtype=torch.long)\n",
    "long_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9., 36., 81.])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor_operated = float_32_tensor * long_tensor\n",
    "print(tensor_operated)\n",
    "print(tensor_operated.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix multiplication (dot product)\n",
    "\n",
    "There are two main rules that performing matrix multiplication needs to satisfy:\n",
    "1. The **inner dimentions** must match\n",
    "2. The resulting matrix has the shape of the **outer dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10    # Does not resign the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)    # Pytorch in-built functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor, 10)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sub(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication (dot product)\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**.    \n",
    "A **transpose** switches the axes or dimentions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      3\u001b[0m                         [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      4\u001b[0m                         [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]])\n\u001b[0;32m      5\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      6\u001b[0m                         [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m      7\u001b[0m                         [\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m12\u001b[39m]])\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m# the same as torch.matmul (it's an alias)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                        [3,4],\n",
    "                        [5,6]])\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                        [8,11],\n",
    "                        [9,12]])\n",
    "torch.mm(tensor_A, tensor_B)    # the same as torch.matmul (it's an alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8,  9],\n",
       "        [10, 11, 12]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A @ tensor_B.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "torch.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "* Reshaping: reshapes an input tensor to a definded shape\n",
    "* View: Retrun a view of an input tensor of certain shape but **keep the same memory as the original tensor** \n",
    "* Stacking: combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze: removes all `1` dimensions from a tensor\n",
    "* Unsqueeze: add a `1` dimensions to a target tensor\n",
    "* Permute: Return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.Size([9]), 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,10)\n",
    "x, x.shape, x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]]), torch.Size([1, 9]), 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped, x_reshaped.shape, x_reshaped.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(3,3)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5, 2, 3],\n",
       "         [5, 5, 6],\n",
       "         [5, 8, 9]]),\n",
       " tensor([5, 2, 3, 5, 5, 6, 5, 8, 9]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:,0] = 5    # a view of tensor shares the same memory as the original\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 2, 3],\n",
       "         [5, 5, 6],\n",
       "         [5, 8, 9]]),\n",
       " tensor([0, 2, 3, 5, 5, 6, 5, 8, 9]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] = 0\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 2, 3, 5, 5, 6, 5, 8, 9],\n",
       "         [0, 2, 3, 5, 5, 6, 5, 8, 9],\n",
       "         [0, 2, 3, 5, 5, 6, 5, 8, 9],\n",
       "         [0, 2, 3, 5, 5, 6, 5, 8, 9]]),\n",
       " torch.Size([4, 9]),\n",
       " 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x,x,x,x], dim=0)    # only until x ndim limits\n",
    "x_stacked, x_stacked.shape, x_stacked.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0, 0],\n",
       "         [2, 2, 2, 2],\n",
       "         [3, 3, 3, 3],\n",
       "         [5, 5, 5, 5],\n",
       "         [5, 5, 5, 5],\n",
       "         [6, 6, 6, 6],\n",
       "         [5, 5, 5, 5],\n",
       "         [8, 8, 8, 8],\n",
       "         [9, 9, 9, 9]]),\n",
       " torch.Size([9, 4]),\n",
       " 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x,x,x,x], dim=1)    # only until x ndim limits\n",
    "x_stacked, x_stacked.shape, x_stacked.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 3],\n",
       "        [5, 5, 6],\n",
       "        [5, 8, 9]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 2, 3],\n",
       "          [5, 5, 6],\n",
       "          [5, 8, 9]],\n",
       " \n",
       "         [[0, 2, 3],\n",
       "          [5, 5, 6],\n",
       "          [5, 8, 9]],\n",
       " \n",
       "         [[0, 2, 3],\n",
       "          [5, 5, 6],\n",
       "          [5, 8, 9]],\n",
       " \n",
       "         [[0, 2, 3],\n",
       "          [5, 5, 6],\n",
       "          [5, 8, 9]]]),\n",
       " torch.Size([4, 3, 3]),\n",
       " 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_stacked = torch.stack([z,z,z,z], dim=0)    # dim으로 지정된 차원의 것을 똑같이 쌓는다고 생각.\n",
    "z_stacked, z_stacked.shape, z_stacked.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 2, 3],\n",
       "          [0, 2, 3],\n",
       "          [0, 2, 3],\n",
       "          [0, 2, 3]],\n",
       " \n",
       "         [[5, 5, 6],\n",
       "          [5, 5, 6],\n",
       "          [5, 5, 6],\n",
       "          [5, 5, 6]],\n",
       " \n",
       "         [[5, 8, 9],\n",
       "          [5, 8, 9],\n",
       "          [5, 8, 9],\n",
       "          [5, 8, 9]]]),\n",
       " torch.Size([3, 4, 3]),\n",
       " 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_stacked = torch.stack([z,z,z,z], dim=1)\n",
    "z_stacked, z_stacked.shape, z_stacked.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 0, 0, 0],\n",
       "          [2, 2, 2, 2],\n",
       "          [3, 3, 3, 3]],\n",
       " \n",
       "         [[5, 5, 5, 5],\n",
       "          [5, 5, 5, 5],\n",
       "          [6, 6, 6, 6]],\n",
       " \n",
       "         [[5, 5, 5, 5],\n",
       "          [8, 8, 8, 8],\n",
       "          [9, 9, 9, 9]]]),\n",
       " torch.Size([3, 3, 4]),\n",
       " 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_stacked = torch.stack([z,z,z,z], dim=2)\n",
    "z_stacked, z_stacked.shape, z_stacked.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 3, 5, 5, 6, 5, 8, 9]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 2, 3, 5, 5, 6, 5, 8, 9]), torch.Size([9]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.squeeze(), x_reshaped.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 2, 3, 5, 5, 6, 5, 8, 9]]]), torch.Size([1, 1, 9]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.unsqueeze(dim=0), x_reshaped.unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 2, 3, 5, 5, 6, 5, 8, 9]]]), torch.Size([1, 1, 9]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.unsqueeze(dim=1), x_reshaped.unsqueeze(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0],\n",
       "          [2],\n",
       "          [3],\n",
       "          [5],\n",
       "          [5],\n",
       "          [6],\n",
       "          [5],\n",
       "          [8],\n",
       "          [9]]]),\n",
       " torch.Size([1, 9, 1]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.unsqueeze(dim=2), x_reshaped.unsqueeze(dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.permute: rearranges the dimensions of a target tensor in a specified order\n",
    "# permuted: same memory with original!!\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "x_permuted = x_original.permute(2, 0, 1)\n",
    "x_permuted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.), tensor(7.))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0,0,0] = 7\n",
    "x_original[0,0,0], x_permuted[0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing(selecting data from tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 10).reshape(1,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), tensor([1, 2, 3]), tensor([1, 2, 3]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0], x[0][0], x[0,0,:]    # SAME!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th and 1st dimensions but only index 1 of 2nd dimension\n",
    "x[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0 dimension but only the 1 index value of 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of oth and 1st dimension and all values of 2nd dimension\n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch tensors & numpy\n",
    "* Data in Numpy -> Pytorch tensor: `torch.from_numpy(ndarray)`\n",
    "* Pytorch tensor -> Numpy: `torch.Tensor.numpy()`     \n",
    "they don't share the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)    # when converting from numpy -> default dtype: float64\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.type(torch.float32)    # We should convert default dtype of Pytorch\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducbility (trying to take random out of random)\n",
    "To reduce the randomness in neural networks and Pytorch comes the concept of a **random seed**.     \n",
    "Essentially what the random seed does is \"flavour\" the randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1945, 0.4086, 0.8320, 0.0192],\n",
       "         [0.6327, 0.9805, 0.8834, 0.7515],\n",
       "         [0.5601, 0.8400, 0.9890, 0.7195]]),\n",
       " tensor([[0.4450, 0.7223, 0.5153, 0.4291],\n",
       "         [0.4805, 0.5462, 0.2975, 0.2835],\n",
       "         [0.4313, 0.8288, 0.5965, 0.6009]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor_A = torch.rand(3,4)\n",
    "random_tensor_B = torch.rand(3,4)\n",
    "\n",
    "random_tensor_A, random_tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2961, 0.5166, 0.2517, 0.6886],\n",
       "         [0.0740, 0.8665, 0.1366, 0.1025],\n",
       "         [0.1841, 0.7264, 0.3153, 0.6871]]),\n",
       " tensor([[0.2961, 0.5166, 0.2517, 0.6886],\n",
       "         [0.0740, 0.8665, 0.1366, 0.1025],\n",
       "         [0.1841, 0.7264, 0.3153, 0.6871]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)    # each time!\n",
    "random_tensor_D = torch.rand(3,4)\n",
    "\n",
    "random_tensor_C, random_tensor_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running tensors and Pytorch objects on the GPUs (and making faster computations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU access with Pytorch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor.device    # default is cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_in_gpu = tensor.to(device)\n",
    "tensor_in_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtensor_in_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "tensor_in_gpu.numpy()    # numpy can't run in GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_in_cpu = tensor_in_gpu.cpu()\n",
    "tensor_in_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_in_cpu.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_in_cpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNL8q+fStOeu1CuhiqEcK1C",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
